<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Advanced Recursion Coding &amp; Analysis</title><link rel="stylesheet" href="../../../../../styles.css"></head><body><article id="5df0c658-ddec-43fd-8bb8-2650a725effd" class="page sans"><header><h1 class="page-title">Advanced Recursion Coding &amp; Analysis</h1><p class="page-description"></p></header><div class="page-body"><ul id="96c6bcf4-bc21-4600-938c-617ef3dd0807" class="toggle"><li><details close=""><summary><strong>Session Flow (5 minutes read)</strong></summary><ul id="ae885002-41cc-404e-b6bd-a62fb48217c6" class="bulleted-list"><li style="list-style-type:disc"><strong>Learning Objective (5 minutes read)</strong><ul id="e04754d3-9e84-47b1-9169-f59579b46978" class="bulleted-list"><li style="list-style-type:circle">Introduction</li></ul><ul id="30f7bffb-d63c-4081-aede-c544bf3b3a51" class="bulleted-list"><li style="list-style-type:circle">Theme</li></ul><ul id="fa485630-1a4f-4cbb-976c-88e2a30adc5f" class="bulleted-list"><li style="list-style-type:circle">Primary Goals</li></ul></li></ul><ul id="3d7d1c7c-0d16-45c2-9329-5ad945ad3a3d" class="bulleted-list"><li style="list-style-type:disc"><strong>Advanced Recursion Coding &amp; Analysis (120 minutes read)</strong><ul id="bad9bafd-3288-4a59-a0f3-f9a545e26f31" class="bulleted-list"><li style="list-style-type:circle">Introduction to Recursion Algorithm Analysis</li></ul><ul id="dc374a68-d4a1-4598-93bb-5add9866398c" class="bulleted-list"><li style="list-style-type:circle">Time-complexity Analysis of the Recursion Algorithm</li></ul><ul id="03aee236-7942-4c48-a3e5-d0d823e1c6d5" class="bulleted-list"><li style="list-style-type:circle">How to find the time complexity of recursive algorithms?</li></ul><ul id="3eacd842-d2c2-4ec2-842d-fccb695b2620" class="bulleted-list"><li style="list-style-type:circle">Explore analysis of the following recursive algorithms</li></ul><ul id="987790d1-9955-4a1c-9ab1-42702cd7ac68" class="bulleted-list"><li style="list-style-type:circle"><strong>Do it yourself</strong></li></ul><ul id="d76accbb-4475-4139-9890-1e1b6f0bb206" class="bulleted-list"><li style="list-style-type:circle">Space-complexity Analysis of the Recursive Algorithm<ul id="e0eb3907-8ceb-4052-96af-e874c5ba5834" class="bulleted-list"><li style="list-style-type:square">Representation of Space Complexity</li></ul><ul id="55aa4a08-7c3a-4d88-b64a-f0f135c7830f" class="bulleted-list"><li style="list-style-type:square">Space used by recursive algorithms</li></ul></li></ul><ul id="dbaf45b2-e570-4b3f-b9c7-c48d8d828ccf" class="bulleted-list"><li style="list-style-type:circle">Space Complexity of Various Sorting Algorithms</li></ul><ul id="4073f41f-7e97-4adf-9cac-48fa528f8a1d" class="bulleted-list"><li style="list-style-type:circle"><strong>Activity 1</strong></li></ul><ul id="c6eddc66-870e-40c2-9ca1-5edae0c856d7" class="bulleted-list"><li style="list-style-type:circle">Determining Optimal Recursion Algorithms for Specific Problems</li></ul><ul id="7b0eb828-bd2c-4c81-9fee-7ebd55577bc4" class="bulleted-list"><li style="list-style-type:circle">Tradeoffs between Time and Space Complexity in recursion Algorithms</li></ul><ul id="4d2af457-6971-44ee-b6ca-f1e3ad84ba95" class="bulleted-list"><li style="list-style-type:circle">Real-World Applications of Recursion Algorithm</li></ul><ul id="13af3ad5-90b3-4b77-9eac-4143258caf2f" class="bulleted-list"><li style="list-style-type:circle"><strong>Explore Further</strong></li></ul></li></ul><ul id="f07ef2c8-2383-4b4a-8a12-25de512b12e9" class="bulleted-list"><li style="list-style-type:disc"><strong>Summary (10 minutes read)</strong><ul id="88162c2a-d375-4432-b776-922428aee04f" class="bulleted-list"><li style="list-style-type:circle">What did we learn?</li></ul><ul id="da9ee27f-e3c1-43a0-904d-910d8bc72205" class="bulleted-list"><li style="list-style-type:circle">Shortcomings &amp; Challenges</li></ul><ul id="85239730-bc0c-4c7a-857d-6606cb55c189" class="bulleted-list"><li style="list-style-type:circle">Best Practices</li></ul><ul id="a357671f-f9ac-426c-8068-ac23b5b8a43b" class="bulleted-list"><li style="list-style-type:circle">Enhance Your Knowledge</li></ul></li></ul></details></li></ul><p id="ea245cf3-33da-4105-84f6-cc27a261e3a5" class="">
</p><h1 id="0770c73c-6d60-4ac8-bf49-a697c5df9ea3" class=""><mark class="highlight-brown">Learning Objective</mark></h1><h2 id="3cb0035c-6a14-4c9c-af41-786d44892c4b" class="block-color-default"><mark class="highlight-red">Introduction</mark></h2><p id="eb77e26b-e42e-495a-b1db-f5b0f3f511c2" class="">Advanced recursion in JavaScript is a powerful tool that allows you to solve complex problems in a way that is both elegant and efficient.</p><p id="944a1f15-f00c-4121-bc2c-5cab77ba6de2" class=""><strong>Duration:</strong> 2 Hours</p><p id="6e8f750f-8ce8-40aa-8d09-bffb20d016cf" class=""><strong>Focus:</strong> Introduction to Recursion, Time and Space Complexity Analysis of recursion algorithms, Real world applications</p><p id="10dc9126-2d39-47de-98ef-70a5ba3a5f42" class=""><strong>Prerequisites:</strong> JavaScript</p><h2 id="ea186ac0-1bea-4fc7-9491-4e38154abe40" class="block-color-default"><mark class="highlight-red">Theme</mark></h2><p id="37339b91-ee62-430e-b78a-7a0e3e803d97" class=""><strong>Pixar Animation Studios</strong> is a company in<strong> </strong>the<strong> </strong>field of computer graphics and animation. Pixar is known for its visually stunning animated films, often featuring complex 3D graphics and animations. To create these graphics, animators use sophisticated algorithms and techniques, including advanced recursion.</p><p id="06a28176-7cf7-4693-8ee8-1b08590aded9" class="">For example, a Pixar animator may need to create a complex 3D model of a character or object, which requires breaking the model into smaller, more manageable parts. Advanced recursion in JavaScript can be used to generate these smaller parts and then recursively assemble them into a larger, more complex model.</p><p id="73a25dc2-1e47-4a72-a54a-0a04c998eb4a" class="">Additionally, advanced recursion can be used to optimize the rendering of these 3D models, ensuring that they are rendered quickly and efficiently on screen. This process involves recursively traversing the model and rendering each component, then recursively assembling them into the final image.</p><p id="bb9c6672-a14c-4c8a-8795-865cac2582b0" class="">By using advanced recursion in JavaScript, Pixar can create visually stunning and complex animations with greater ease and efficiency, leading to higher-quality productions and more engaged audiences.</p><h2 id="63eac2cd-8b54-4bce-80e5-e32340af57b4" class="block-color-default"><mark class="highlight-red">Primary Goals</mark></h2><ul id="f7edf006-a044-4b5f-9463-fb9596490001" class="bulleted-list"><li style="list-style-type:disc">To analyze the performance of recursive algorithms and understand their time complexity, which measures how the algorithm&#x27;s runtime scales with the input&#x27;s size.</li></ul><ul id="67c348b9-8b52-4c67-928f-66af4658869b" class="bulleted-list"><li style="list-style-type:disc">To understand the space complexity of recursive algorithms, the amount of memory required to run, and how it scales with the input size.</li></ul><ul id="ed3ec499-1107-424f-bcb0-48c011a077ea" class="bulleted-list"><li style="list-style-type:disc">To learn how to use Big O notation to express the time and space complexity of recursive algorithms and how to compare the performance of different algorithms.</li></ul><ul id="c201f550-ad8e-4d45-9e09-a5a31e6dcba6" class="bulleted-list"><li style="list-style-type:disc">To apply these concepts to real-world programming problems and to understand how the choice of algorithm and data structure can impact the performance of a program.</li></ul><p id="67a37b46-4559-4e63-afab-319f1f684b3a" class="">
</p><h1 id="00a7e47d-681e-4ee8-ac6e-1f413f2a722b" class=""><mark class="highlight-brown">Advanced Recursion Coding &amp; Analysis</mark></h1><h2 id="cc682fd2-933b-48ef-979e-770088fa856f" class="block-color-default"><mark class="highlight-red">Introduction to Recursion Algorithm Analysis</mark></h2><p id="b46de877-fafd-4e1e-9a0b-3a6baa16ccd9" class="">Recursive algorithms are essential to computer science but can be challenging to analyze. Understanding a recursive algorithm&#x27;s time and space complexity is critical to ensure it runs efficiently. Time complexity measures how long an algorithm takes to run, while space complexity measures how much memory it requires. In this topic, we will dive into the world of recursive algorithms, how it works, and learn how to analyze their time and space complexity. We will explore various techniques for analyzing recursive algorithms, including recursion trees, big O notation, and mathematical formulas. So, let&#x27;s explore the fascinating world of time and space complexity analysis of recursive algorithms.</p><h2 id="def55c5e-1346-454c-8101-f267596e4cbd" class=""><mark class="highlight-red">Time-complexity Analysis of the Recursion Algorithm</mark></h2><p id="baec2b02-1913-4026-b5c6-63d726868d3a" class="">Sometimes programmers find it challenging to analyze recursive algorithms due to their mathematical details. But working with recursive algorithms becomes easy when we understand recursive patterns and methods used in the analysis. Without delaying further, let&#x27;s learn fundamental concepts related to recursion time complexity</p><h3 id="6054ec6e-13d6-4fa2-8f7f-f25c105385c6" class="block-color-default">What is the recurrence relation of a recursive function?</h3><p id="e7a7edd9-ea8d-46bf-a777-cd84f099ce24" class="">A recurrence relation is an equation that describes a sequence where any term is defined using its previous terms. We use recurrence relations to analyze the time complexity of recursive functions regarding input size. </p><p id="db6e1d82-d83b-43b4-83b9-a77c33768e2c" class="">In the case of recursion, we solve a problem by breaking it down into smaller subproblems. If the time complexity of a recursive function is T(n), then the time complexity of the smaller subproblems will be defined by the same function but in terms of the subproblem&#x27;s input size. </p><figure id="f9583f85-9991-4484-8cf4-84b06cb8973d" class="image"><img style="width:2368px" src="Advanced%20Recursion%20Coding%20&amp;%20Analysis%205df0c658ddec43fd8bb82650a725effd/Screenshot_2023-05-10_at_7.41.36_PM.png"/></a></figure><p id="d097d70c-e2c3-4225-af8c-44e33a783932" class="">Here is a common approach to writing T(n) if we have k number of subproblems: T(n) = T(input size of 1st subproblem) + T(input size of 2nd subproblem) + .... + T(input size of kth subproblem) + Time complexity of additional operations other than recursive calls. </p><p id="68cde66d-3f4b-4140-b992-46cfcb54ba7d" class="">The above formula provides an approach to defining the recurrence relation of every recursive algorithm. We solve this recurrence relation and calculate the overall time complexity for recursion in Big-O notation. Let&#x27;s better understand this via examples of various recurrence relations of popular recursive algorithms.</p><p id="29b4bfdd-fc05-40c2-9fee-64224731e9ab" class="">
</p><p id="edc04979-5d83-41f8-af82-60d186174c0a" class=""><strong>Decrease by a constant: Reverse an array</strong></p><pre id="365c9aa2-6948-4af3-a79d-84e3e8e5d186" class="code"><code>reverse (A[], l, r)
- swap(A[l], A[r])
- reverse(A, l + 1, r - 1)
- Base Case: if (l &gt;= r), then return</code></pre><p id="8d8dbbd8-20b1-4a47-960b-cfbd2dcc3c29" class="">We are reversing an n-size array by swapping the first and last values and recursively solving the remaining subproblem of reversing an (n - 2) size array. At each step of recursion, the input size decreases by 2.</p><ul id="ea520030-8bc6-414f-9f06-7d603c0fcaa3" class="bulleted-list"><li style="list-style-type:disc">Time complexity T(n) = Time complexity of solving (n - 2) size problem +Time complexity of the swapping operation = T(n - 2) + O(1).</li></ul><ul id="6db27225-1274-401e-b641-baa3b5d20d30" class="bulleted-list"><li style="list-style-type:disc">Recurrence relation to reverse an array: T(n) = T(n - 2) + c, where T(1) = c</li></ul><p id="3d6f0a0b-14ca-462c-881e-ccb6291ee0cd" class="">
</p><p id="57695e2d-0c72-4cda-8ddf-0183dfd04de6" class=""><strong>Decrease by a constant factor: Binary Search</strong></p><pre id="f916abd3-e396-4241-a688-8d1eb2c30d3e" class="code"><code>binarySearch(A[], l, r, target)
- if (A[mid] == target), return mid
- if (A[mid] &gt; target), binarySearch(A, l, mid - 1, target)
- if (A[mid] &lt; target), binarySearch(A, mid + 1, r, target)
Base case: If (l &gt; r), then return -1</code></pre><p id="ca9e6b6e-9f20-4a63-95cd-86c0b53b15ba" class="">At each recursion step, we do one comparison and decrease the input size by half. In other words, we are solving the problem of n size using the solution of one subproblem of input size n/2 (Based on the comparison, either left or right sub-problem).</p><ul id="0851531a-5f95-40cd-9bc8-ecac446627b7" class="bulleted-list"><li style="list-style-type:disc">Time complexity T(n) = Time complexity of n/2 size problem + Time complexity of comparison operation = T(n/2) + O(1).</li></ul><ul id="65889c20-58a1-421a-b6ef-d58d9277591b" class="bulleted-list"><li style="list-style-type:disc">Recurrence relation of binary search: T(n) = T(n/2) + c, where T(1) = c</li></ul><p id="6db490b7-a8b1-47f5-aec9-10ceb39ce01f" class="">
</p><p id="b75b4846-aac2-4a2a-b01d-d7620788a354" class=""><strong>Dividing into two equal-size subproblems: Merge sort</strong></p><pre id="0e982178-340c-40df-9058-0516203d1bcb" class="code"><code>mergeSort (A[], l, r)
- mid = l + (r - l)/2
- mergeSort(A, l, mid)
- mergeSort(A, mid + 1, r)
- merge(A, l, mid, r)

Base case: if (l == r), then return</code></pre><p id="8871c1d3-2808-48b8-b7b9-62029a7268a5" class="">In merge sort, we are solving the problem of n size by using a solution of two equal subproblems of input size n/2 and merging sub-problems solution in O(n) time.</p><ul id="606d0e0a-923d-4023-aa20-cb49c016a50c" class="bulleted-list"><li style="list-style-type:disc">Time complexity T(n) = Time complexity of left sub-problem of size n/2 +Time complexity of right sub-problem of size n/2 + Time complexity of merging = T(n/2) + T(n/2) + O(n) = 2 T(n/2) + cn </li></ul><ul id="e8a6f3e2-6c33-4725-ac47-1663c5b2888c" class="bulleted-list"><li style="list-style-type:disc">Recurrence relation of merge sort: T(n) = 2T(n/2) + cn, where T(1) = c</li></ul><p id="52ce6525-f621-4f07-83fb-91930c12ff43" class="">
</p><p id="32704dc6-c1dd-4d78-9f3c-b01bfea32a9a" class=""><strong>Dividing into two different size subproblems: Quick sort</strong></p><pre id="42b4bec9-38c6-4d49-a223-01beef8aa012" class="code"><code>quickSort(A[], l, r)
- pivot = partition(A, l, r)
- quickSort(A, l, pivot - 1)
- quickSort(A, pivot + 1, r)

Base case: if (l &gt;= r), then return</code></pre><p id="71cb800e-5f08-4811-9de0-7da31b025534" class="">In quick sort, we divide an array into two subarrays in O(n) time and recursively solve the subproblems. The size of the subarrays depends on the choice of pivot in the partition algorithm. Let i be the number of elements in the left subarray (left of the pivot), and n - i - 1 be the number of elements in the right subarray (right of the pivot). Then, the size of the left subproblem is
i and the size of the right subproblem is n - i - 1.</p><ul id="83940eb4-2b29-452e-a18a-6c58e411cbab" class="bulleted-list"><li style="list-style-type:disc">Time complexity T(n) = Time complexity of partition algorithm + Time complexity of left sub-problem of size i + Time complexity of right subproblem of size (n - i - 1) = O(n) + T(i) + T(n - i - 1) = T(i) + T(n - i - 1) + cn.</li></ul><ul id="fd47ea1e-8717-4f10-8462-ddbed30d7fb6" class="bulleted-list"><li style="list-style-type:disc">Recurrence relation of quick sort: T(n) = T(i) + T(n - i - 1) + cn, where T(1) = c.</li></ul><p id="bdba9f46-8482-485c-84cb-05d919836a95" class="">
</p><p id="b23efb26-6faa-418b-be9f-0adc297e60ea" class=""><strong>Dividing into more than two subproblems of equal size</strong></p><p id="555a6da8-b51c-484a-a8e0-a90de24b568d" class=""><span style="border-bottom:0.05em solid"><strong>Karatsuba algorithm for fast multiplication:</strong></span> We solve the integer multiplication problem of size n bits using three sub-problems of size n/2 bits and combine these solutions in O(n) time. <strong>Recurrence relation:</strong> T(n) = 3T(n/2) + cn, where T(1) = c.</p><p id="0862c7cb-99b2-4380-942a-b306106189a6" class=""><span style="border-bottom:0.05em solid"><strong>Strassen’s matrix multiplication:</strong></span><strong> </strong>Here, we solve the matrix multiplication problem of size n using a solution of seven sub-problems of size n/2 and combining these solutions in O(n^2) time. <strong>Recurrence relation:</strong> T(n) = 7T(n/2) + cn^2, where T(1) = c.</p><p id="9db0456c-129e-4b94-9a15-a73af7ce236d" class="">
</p><p id="7b197a82-35d1-46e0-82cf-46189cb0e2b0" class=""><strong>Dividing into two dependent subproblems: Finding the nth Fibonacci</strong></p><pre id="f21ea85d-9695-45fc-aa17-04f9b2cb2194" class="code"><code>fib (n) = fib (n - 1) + fib (n - 2)
Base case: if (n &lt;= 1), return n
Here we have 2 base cases: fib(0) = 0 and fib(1) = 1</code></pre><p id="c3e1c1e2-31a4-478e-83bb-54a64dfb11f5" class="">For finding the nth Fibonacci, we are recursively solving and adding two subproblems of size (n - 1) and (n - 2). Both subproblems depend on each other because the value of (n - 1)th Fibonacci depends on the value of (n - 2)th Fibonacci, and so on. Such type of dependent subproblems arises in case of <strong>optimization problems in dynamic programming</strong></p><ul id="516f2978-f9d7-491f-9e3d-0312e87d0adb" class="bulleted-list"><li style="list-style-type:disc">Time complexity T(n) = Time complexity of finding (n - 1)th Fibonacci + Time complexity of finding (n - 2)th Fibonacci + Time complexity of addition = T(n - 1) + T(n - 2) + O(1)</li></ul><ul id="4afd3662-9d26-43d9-8614-402f153f0419" class="bulleted-list"><li style="list-style-type:disc">Recurrence relation of finding nth Fibonacci: T(n) = T(n - 1) + T(n - 2) + c,
where T(n) = c for n &lt;= 1.</li></ul><h2 id="bc484b26-8892-458d-a87c-a27a882d47f4" class=""><mark class="highlight-blue">Do it yourself</mark></h2><p id="ec517968-2a4b-4dc2-8833-402c73d65cdd" class=""><strong>Match the following:</strong></p><div id="722a8577-a721-407d-9356-06c95da7ebd8" class="column-list"><div id="1eee0afc-e8a3-4d64-81e2-9256f7ff336b" style="width:100%" class="column"><p id="27cb9cad-8e9c-46ee-8ec9-926b594840a2" class="">A) Fibonacci sequence</p><p id="b04652ab-91a4-4f41-b84d-e4fac4da4ce6" class="">B) Binary search</p><p id="02f7d5a1-390c-4ffe-86ef-aa8293efddca" class="">C) Merge sort</p><p id="473b2af8-38de-4e57-a65c-feea06ff4fbe" class="">D) Quick sort</p><p id="7582a70f-5599-4e09-8988-d7b7563fbef6" class="">E) Strassen Matrix Multiplication</p><p id="4ef263c4-49c5-45d3-a6e6-90fece65b878" class="">F) Karatsuba Algorithm</p></div><div id="f77de76b-3646-4b90-9383-f34096d64e48" style="width:100%" class="column"><p id="59bdf87b-189a-4b87-a52f-2640dd84f2a9" class="">a) T(n) = T(n/2) + O(1)</p><p id="469db3c2-c444-4a58-8ace-4416c241e975" class="">b) 2 * T(n/2) + O(n)</p><p id="0d3a777f-0b81-44e8-aeb4-fe0eacbe2a80" class="">c) T(n) = 7 * T(n/2) + O(n^2)</p><p id="63a6f45b-d631-47e7-85c3-c8d1bc7f9a88" class="">d) T(n) = T(n-1) + T(n-2) + O(1)</p><p id="cca42788-bc93-4bd1-a92f-7bc957a615f3" class="">e) T(n) = 3 * T(n/2) + O(n)</p><p id="817e58d8-8ad7-4dd7-9cf1-550642a1346f" class=""> f) T(k) + T(n-k-1) + O(n)</p></div></div><ul id="5c7e02c8-d460-427e-83a4-5bcece07541a" class="toggle"><li><details close=""><summary><strong>Answers</strong></summary><ol type="1" id="797a99e3-4950-4417-b798-3b4ef242c2ae" class="numbered-list" start="1"><li>A) Fibonacci sequence: T(n) = T(n-1) + T(n-2) + O(1)</li></ol><ol type="1" id="bb308384-6216-4586-8232-1cf473c3567e" class="numbered-list" start="2"><li>Binary search: T(n) = T(n/2) + O(1)</li></ol><ol type="1" id="9901f732-e4c5-4828-a852-e178c55f1d60" class="numbered-list" start="3"><li>Merge sort: T(n) = 2 * T(n/2) + O(n)</li></ol><ol type="1" id="f647f4b5-f53f-41e3-aff4-52eb576e5723" class="numbered-list" start="4"><li>Quick sort: T(n) = T(k) + T(n-k-1) + O(n)</li></ol><ol type="1" id="8fab1d27-155e-4061-a62a-aad479dcf05d" class="numbered-list" start="5"><li>Strassen Matrix Multiplication: T(n) = 7 * T(n/2) + O(n^2)</li></ol><ol type="1" id="9551a3e7-3054-47f6-81c0-ed5ef2f9dd8b" class="numbered-list" start="6"><li>Karatsuba Algorithm (for Multiplication): T(n) = 3 * T(n/2) + O(n)</li></ol></details></li></ul><p id="2add9cfe-625d-49af-b77d-3417a6c6d6a1" class="">
</p><h2 id="a96c5c73-adb6-45f0-a4c5-c6349621835b" class="block-color-default"><mark class="highlight-red">How to find the time complexity of recursive algorithms?</mark></h2><p id="1e4e3611-7b6c-4390-8bff-21f8d4a489c2" class=""><strong>Step 1: Identify input size and smaller subproblems</strong></p><ul id="daadf60c-f63f-4784-9d33-d6724e22f89c" class="bulleted-list"><li style="list-style-type:disc">We first identify the input size of the larger problem.</li></ul><ul id="d921eab6-b07e-423e-94a6-9697c21769f4" class="bulleted-list"><li style="list-style-type:disc">Then we recognize the total number of smaller sub-problems.</li></ul><ul id="03e4febc-ee34-463a-9cea-4346887e5494" class="bulleted-list"><li style="list-style-type:disc">Finally, we identify the input size of smaller sub-problems.</li></ul><p id="bb687261-fc21-4396-af0b-fcfbbac7cf35" class=""><strong>Step 2: Write the recurrence relation for the time complexity</strong></p><ul id="a41ef187-5da8-4e6c-a302-323cacbeb307" class="bulleted-list"><li style="list-style-type:disc">We define the time complexity function for the larger problem regarding the input size. For example, if the input size is n, the time complexity function would be T(n).</li></ul><ul id="db1c24b3-ed1f-4503-9b2e-76d3257e75cc" class="bulleted-list"><li style="list-style-type:disc">Then we define the time complexity of smaller subproblems. For example, in the case of merge sort, the input size of both subproblems is n/2 each, so the time complexity of each subproblem would be T(n/2).</li></ul><ul id="14c6b9f7-37a2-49f5-80af-069389a9bb62" class="bulleted-list"><li style="list-style-type:disc">Next, we analyze the worst-case time complexity of additional operations. For example, in merge sort, the divide (O(1)) and merging process (O(n)) are extra operations that we need to perform to get the larger sorted array.</li></ul><ul id="6b5801a2-d8c8-47a5-a173-2dce952eb134" class="bulleted-list"><li style="list-style-type:disc">We add the time complexities of the sub-problems and additional operations to get the overall time complexity function T(n) equation.</li></ul><ul id="75f7116d-fed5-4c8c-9838-020d0eceb46d" class="bulleted-list"><li style="list-style-type:disc">We also define the time complexity of the base case, i.e., the smallest version of the problem. Our solution to the recurrence depends on this, so we need to define it correctly. Think!</li></ul><p id="38b6eb84-aaec-45fc-bab4-f7ef27af106b" class=""><strong>Step 3: Solving recurrence relation to get the time complexity</strong></p><p id="ab936d97-7655-4821-b052-81df4b94867a" class="">We mainly use the following two methods to solve recurrence relations in algorithms and data structure. We can choose these methods depending on the nature of the recurrence relation. The master method works best to analyze divide and conquer algorithms, but a recursion tree method is always a fundamental approach applied to all types of recursive algorithms</p><ul id="b56751c8-c5a5-47f7-a391-d3882548e5b3" class="bulleted-list"><li style="list-style-type:disc"><strong>Method 1:</strong> Recursion Tree Method</li></ul><ul id="3df4f7a7-886e-4179-859e-ba0500ba4451" class="bulleted-list"><li style="list-style-type:disc"><strong>Method 2:</strong> Master Theorem</li></ul><h3 id="4f0a534a-45d0-4188-8848-b92fce541065" class="">Method 1: Analysis of recursion using Recursion Tree Method</h3><p id="e5901330-6c8a-4a02-8e10-a021fdd1c585" class="">A recursion tree is a tree diagram of recursive calls where each tree node represents the cost of a certain subproblem. The idea is simple! The time complexity of recursion depends on two factors: 1) The total number of recursive calls and 2) The time complexity of additional operations for each
recursive call.
So a recursion tree is a diagram representing the additional cost for each recursive call in terms of its input size. We should add the extra cost for each recursive call to get the overall time complexity. One of the best ideas is to perform this cost sum level by level.</p><p id="9000e3c0-b78e-4c03-b4da-5278f1ddca59" class=""><strong>Steps of analysis using the recursion tree method</strong></p><ul id="218d9cd6-7e73-44ef-abfe-9d0b8a595434" class="bulleted-list"><li style="list-style-type:disc">Draw a recursion tree of given recurrence relation.</li></ul><ul id="ab80fe7c-a3e9-4bd0-ae78-b4f3852d13c3" class="bulleted-list"><li style="list-style-type:disc">Calculate the total number of levels in the recursion tree.</li></ul><ul id="980b80ba-2d9b-403f-87fb-c8b1de014d42" class="bulleted-list"><li style="list-style-type:disc">Calculate the cost of additional operations at each level by adding the cost of each node present at the same level.</li></ul><ul id="353392e5-0f74-4c75-8347-32f442309b5e" class="bulleted-list"><li style="list-style-type:disc">Finally, add the cost of each level to determine the total cost of recursion. We simplify this expression and find the overall time complexity in big O notation.</li></ul><p id="af13d002-b48c-41f5-94ab-e80f3e938178" class=""><strong>Example: Analysis of merge sort using recursion tree method</strong></p><p id="43735594-5d64-4f76-80c6-49309761a27a" class="">Merge sort recurrence relation: T(n) = 2T(n/2) + cn, T(1) = c.
We are dividing the problem of size n into two different subarrays (subproblems) of size n/2. Here cn represents the cost of merging solutions of smaller sub-problems (smaller sorted arrays of size n/2). So, at each recursion step, the problem will be divided in half until the sub-problem size becomes 1.</p><figure id="6f964b54-86a0-4c74-a0ba-f4537021ba3f" class="image"><img style="width:2384px" src="Advanced%20Recursion%20Coding%20&amp;%20Analysis%205df0c658ddec43fd8bb82650a725effd/Screenshot_2023-05-10_at_7.42.12_PM.png"/></a></figure><ul id="eb990c99-08f4-434d-a00d-776508f5846c" class="bulleted-list"><li style="list-style-type:disc">We start with the term cn as the root, which is the cost of additional operations at the first level of the recursion tree. Left and right children of the root are the time complexity of two smaller sub-problems i.e. T(n/2). </li></ul><ul id="c036353a-462f-4d30-978b-c534009c3bb8" class="bulleted-list"><li style="list-style-type:disc">Now we move one level further by expanding T(n/2).</li></ul><ul id="81aa4e72-b529-4d01-8b95-3d7f19d682ad" class="bulleted-list"><li style="list-style-type:disc">At the second level, there are two nodes, and the additional operation cost at each node is cn/2. So the overall cost of additional operations at the second level of recursion = cn/2 + cn/2 = cn.</li></ul><ul id="c1dbfbd7-d020-499c-ba70-5987d1f8f319" class="bulleted-list"><li style="list-style-type:disc">Similarly, we move to the third level where total cost = cn/4 + cn/4 +cn/4 + cn/4= cn, and so on.</li></ul><ul id="bf9660b6-c4ee-41c6-ae90-d135fb7b162f" class="bulleted-list"><li style="list-style-type:disc">We continue expanding each internal node in the recursion tree similarly until the problem sizes reach 1. The bottom level has n nodes, each</li></ul><ul id="899c102d-06e7-4a5d-af85-0bd73318f1dd" class="bulleted-list"><li style="list-style-type:disc">In general, level i has 2^i nodes, each contributing a cost of cn/2^i, So the total cost of ith level = 2^i (cn/2^i) = cn.</li></ul><figure id="7f7fc950-0c81-44fb-8b7f-f69ce457a8fe" class="image"><img style="width:2400px" src="Advanced%20Recursion%20Coding%20&amp;%20Analysis%205df0c658ddec43fd8bb82650a725effd/Screenshot_2023-05-10_at_7.42.39_PM.png"/></a></figure><p id="2f3b767f-4392-44cd-bf3c-3dff2525838e" class="">Here, recursion tree is a full binary tree structure where each node has two children, and each level is completely full. At each level, input size decreases by the factor of 2, and recursion tree will terminate at input size 1. So the height of recursion tree <strong>h = logn (Think!)</strong></p><ul id="21192fd8-a7a5-44d2-8b79-293f23dcd018" class="bulleted-list"><li style="list-style-type:disc">Total number of level in binary tree = height of the binary tree + 1 = logn + 1</li></ul><ul id="fbdcbc10-8797-4971-b1e3-8918d1de705d" class="bulleted-list"><li style="list-style-type:disc">To compute the total cost represented by the recurrence, we add up the costs of all the levels. The recursion tree has logn + 1 levels, each costing cn. So total cost = cn * (logn + 1) = cnlogn + cn.</li></ul><ul id="d7afe097-eafb-442c-a519-5440dd184bfa" class="bulleted-list"><li style="list-style-type:disc">After Ignoring the low-order term and the constant c in (cnlogn + cn), the
time complexity of merge sort = O(nlogn)</li></ul><p id="04a5a8e1-644c-4f79-9409-1074116d4f52" class="">To explore further, understand the analysis of binary search and quick sort
using recursion tree method.</p><h2 id="b65c68c1-a70d-4af9-88dc-011673033c64" class="">Method 2: Analysis of recursion using Master Theorem</h2><p id="c52545fa-5000-4a31-89e8-f3cbd4a31ead" class="">We use the master method for finding time complexity of divide and conquer algorithm that partition an input into smaller subproblems of equal sizes. It is primarily a direct way to get the solution for recurrences that can be transformed to the type: T(n) = aT(n/b) + O(n^k), where a≥1 and b&gt;1.
The master theorem recurrence describes time complexity of an algorithm that divides a problem of size n into a number of subproblems, each of size <strong>n/b</strong>, where <strong>a</strong> and <strong>b</strong> are positive constants. Here <strong>a</strong> number of subproblems are solved recursively, each in time T(n/b) and O(n^k) is the cost of dividing the problem and combining the solution of subproblems. There are three cases of analysis using the master theorem:</p><p id="6559d363-d845-42b9-b746-c81f83a22c14" class=""><strong>Case 1:</strong> When k &lt; logb(a) then T(n) = O(n^logb(a)) </p><p id="658b6a05-9a25-4c00-948d-59dfe7bb0184" class=""><strong>Case 2:</strong> When k = logb(a) then T(n) = O(n^k * logn) </p><p id="1d2a0c9c-1964-4583-a1fc-5118ffbc92b3" class=""><strong>Case 3:</strong> When k &gt; logb(a) then T(n) = O(n^k)</p><h3 id="843da5e5-8943-4dba-872b-e983113bfc62" class=""><strong>Special Note:</strong></h3><ul id="1b8e37b5-7433-47ff-b9fb-e9afd1673f39" class="bulleted-list"><li style="list-style-type:disc">The general recurrence of the master theorem is T(n) = aT(n/b) + f(n), where f (n) is an asymptotically positive function. For ease of simplicity and application in analysis, we encounter f(n) equal to O(n^k) in most of the coding problems. </li></ul><ul id="9cb63e4a-cc06-43a4-8d4e-da0c480089fc" class="bulleted-list"><li style="list-style-type:disc">The master theorem is derived from the recursion tree method, where the height of the recurrence tree is logb(n). We skip the mathematical details and proof behind this theorem, but they are available in the CLRS book if you are interested in learning more.</li></ul><h3 id="c4c10e47-52a6-42aa-8ee6-3a37c62c5541" class=""><strong>Example 1: Binary search analysis using master theorem </strong></h3><p id="35882485-91ce-4a64-a1f4-d04e644eb6e2" class="">Comparing with master theorem relation with binary search recurrence relation:</p><ul id="0268138f-25f2-481b-b72d-38cb3e382af3" class="bulleted-list"><li style="list-style-type:disc">T(n) = aT(n/b) + O(n^k)</li></ul><ul id="2f451d54-8f82-4dcd-b0ce-e6178553aa95" class="bulleted-list"><li style="list-style-type:disc">T(n) = T(n/2) + c</li></ul><pre id="7da85035-4946-46ae-b6f9-62c185930245" class="code"><code>Here a = 1, b = 2 (a &gt; 1 and b &gt; 1)
k = 0 because n^k = c = Cn^0

=&gt; logb(a) = log2(1) = 0
=&gt; k = logb(a)

We can apply case 2 of the master theorem.</code></pre><p id="b9b62ba0-9f0d-4444-821a-e25958e6777b" class="">T(n) = O(n^k * log(n)) = O(n^0 * log(n)) = O(logn)</p><h3 id="65843491-eda0-4a9d-b682-293772b0f9ba" class=""><strong>Example 2: Merge sort analysis using master theorem</strong></h3><p id="c14722f3-b643-4617-a5fb-2a3d30f43b87" class="">Comparing master theorem recurrence with merge sort recurrence relation:</p><ul id="a637a8cb-0391-4894-a2ad-a6453ab7249c" class="bulleted-list"><li style="list-style-type:disc">T(n) = aT(n/b) + O(n^k)</li></ul><ul id="9c4a6428-b756-43fd-b454-e6b4a3af30c0" class="bulleted-list"><li style="list-style-type:disc">T(n) = 2T(n/2) + cn</li></ul><pre id="86effa4d-4136-4a2e-a3c6-590a5fc44245" class="code"><code>Here a = 2, b = 2 (a &gt; 1 and b &gt; 1)
O(n^k)= cn = O(n¹) =&gt; k = 1

logb(a) = log 2(2) = 1
Hence =&gt; k = logb(a) = 1

We can apply case 2 of the master theorem.</code></pre><p id="7595aa72-ddf4-461c-828c-f82a39bcdf7b" class="">Time Complexity T(n) = O(n^k * log(n)) = O(n^1 * log(n)) = O(nlogn)</p><h3 id="fe47a927-934e-4add-9a1a-ceda39b8cb4b" class=""><strong>Example 3: Divide and conquer idea of finding max and min</strong></h3><p id="e2c88dc8-aca0-443c-b624-bf660072d8ad" class="">Comparing master theorem recurrence with finding max and min recurrence relation:</p><ul id="a6f4cafd-bcf0-47d4-848d-0fe8d7a0f9e1" class="bulleted-list"><li style="list-style-type:disc">T(n) = aT(n/b) + O(n^k)</li></ul><ul id="fba23c03-47cd-4512-91ef-e8a495039f81" class="bulleted-list"><li style="list-style-type:disc">T(n) = 2T(n/2) + c</li></ul><pre id="3676eb14-4d91-4673-a230-7f31ad3a94ec" class="code"><code>Here a = 2, b = 2 (a &gt; 1 and b &gt; 1)
O(n^k)= cn = O(n^0) =&gt; k = 0

=&gt; logb(a) = log 2(2) = 1
=&gt; Hence =&gt; logb(a) &gt; k

We can apply case 1 of the master theorem.</code></pre><p id="5b07bc01-be6d-4791-bdd2-9161e3fe8001" class="">Time Complexity T(n) = O(n^logb(a)) = O(n^1) = O(n)</p><h3 id="75916902-2773-4064-a31c-8c5737e3b635" class=""><strong>Example 4: Analysis of Strassen’s matrix multiplication</strong></h3><p id="e23241d3-c5f8-479b-a1e6-c78e3d950b48" class="">Comparing master theorem recurrence with strassen’s multiplication recurrence:</p><ul id="2804c95b-30d1-4f3f-9088-4a6dca8d6eed" class="bulleted-list"><li style="list-style-type:disc">T(n) = aT(n/b) + O(n^k)</li></ul><ul id="5af06980-992c-4049-99e5-e0690a9dbb01" class="bulleted-list"><li style="list-style-type:disc">T(n) = 7T(n/2) + cn^2</li></ul><pre id="18bf430e-7fd8-4eed-8085-5a60f209d721" class="code"><code>Here a = 7, b = 2 (a &gt; 1 and b &gt; 1)
O(n^k)= cn^2 = O(n^2) =&gt; k = 2

logb(a) = log 2(7) = 2.8 (Approximately)
Hence =&gt; logb(a) &gt; k

so we can apply case 1 of the master theorem.</code></pre><p id="d083b575-7002-427c-a4e5-14610c3fc7f5" class="">Time complexity T(n) = O(n^logb(a)) = O(n^log2(7)) = O(n^2.8)</p><h2 id="669d93d5-a912-4b7c-be59-d5f8c69dd49d" class="block-color-default"><mark class="highlight-red">Explore analysis of the following recursive algorithms</mark></h2><ul id="b05fc6a7-cca0-49cc-8d25-416bb66f2c70" class="bulleted-list"><li style="list-style-type:disc">Finding max element in an array recursively: T(n) = T(n - 1) + O(1)</li></ul><ul id="11917ced-fabe-4385-baa5-16c4c3280ee5" class="bulleted-list"><li style="list-style-type:disc">Recursive insertion sort: T(n) = T(n - 1) + O(n)</li></ul><ul id="c41e4b12-7937-4923-99a1-8d667175a9bb" class="bulleted-list"><li style="list-style-type:disc"><strong>Tower of Hanoi puzzle:</strong> T(n) = 2T(n - 1) + O(1)Finding closest pair of points: T(n) = 2T(n/2) + O(nlogn)</li></ul><ul id="69dd6f60-2683-414a-b9a7-9286ca745a8c" class="bulleted-list"><li style="list-style-type:disc">Divide and conquer algorithm of finding max and min: T(n) = 2T(n/2) +O(1)</li></ul><ul id="d4e9a7dc-1541-494f-9433-bf698bd83f87" class="bulleted-list"><li style="list-style-type:disc"><strong>Divide and conquer algorithm of max subarray sum:</strong> T(n) = 2T(n/2) +O(n)</li></ul><ul id="a1f49a2c-a607-4331-82aa-2bc6af9c4790" class="bulleted-list"><li style="list-style-type:disc">Recursively searching in a balanced BST: T(n) = T(n/2) + O(1)</li></ul><ul id="b7fc4267-746e-4ea5-a4d6-301bc8b0a669" class="bulleted-list"><li style="list-style-type:disc"><strong>DFS traversal of a binary tree:</strong> T(n) = T(i) + T(n - i - 1) + O(1), where in number of nodes are in the left subtree and (n - i - 1) number of nodes in
right subtree</li></ul><ul id="5af3029e-69f7-41f5-ad8c-098d83080cd7" class="bulleted-list"><li style="list-style-type:disc">Average case analysis of <strong>quick-select algorithm of finding kth smallest element:</strong> T(n) = 2/n (i = n/2 to n-1 ∑ T(i)) + cn</li></ul><ul id="ede60540-49d7-4f37-a17b-bb8d91b71d43" class="bulleted-list"><li style="list-style-type:disc">Brute force recursive algorithm of <strong>longest common subsequence:</strong> T(n, m)= T(n-1, m-1) + O(1), if the last values of strings are equal, otherwise T(n,m) = T(n-1, m) + T(n, m-1) + O(1)</li></ul><p id="7ded5f2a-88ae-49e2-9cae-97fd7168b27d" class="">
</p><h2 id="5d3bb342-a7d4-4e55-b797-f00f2d4c1c2d" class=""><mark class="highlight-red">Space-complexity Analysis of the Recursive Algorithm</mark></h2><p id="b43dfab5-e2f6-4ed1-82b7-a826f73f583c" class="">In this tutorial, we will introduce the concept of <code>space complexity</code>. In simple words, it is the amount of memory required to run a program, proportional to the input size that&#x27;s fed in. For computing the space complexity, we ought to consider two factors:</p><ol type="1" id="f6583f5f-b606-4bd1-8545-a7b55fcbe31e" class="numbered-list" start="1"><li><strong>Input space:</strong> Space used by input.</li></ol><ol type="1" id="7dd3cd68-8335-4ae5-aa37-26c8ea65476f" class="numbered-list" start="2"><li><strong>Auxiliary space:</strong> The additional space used by the algorithm, e.g., to hold temporary variables or the space used by the activation stack.</li></ol><h3 id="cef52f6e-3fe5-4508-89c0-eefcf7a7ca73" class="block-color-default"><strong>Representation of Space Complexity</strong></h3><p id="ecbf3bbf-2525-4414-a3e9-5bff17a2771e" class="">Space complexity is generally represented using <a href="https://algodaily.com/lessons/understanding-big-o-and-algorithmic-complexity">big O notation</a> in terms of the size of the input. Big O is a convenient way to let us mathematically express how the space requirements of a program grow with the change in the size of the inputs. Here are a few examples:</p><ul id="01763851-6f14-41c8-a046-627f3e758e91" class="bulleted-list"><li style="list-style-type:disc">An algorithm that uses a single variable has a constant space complexity of <code>O(1)</code>.</li></ul><ul id="44ff19e4-4690-4a93-ae62-a6dbefaacba0" class="bulleted-list"><li style="list-style-type:disc">A method that requires an array of <code>n</code> elements has a linear space complexity of <code>O(n)</code>.</li></ul><ul id="07c9514f-e6f9-47e7-ba2f-01ddd55e56e1" class="bulleted-list"><li style="list-style-type:disc">Computations using <a href="https://algodaily.com/lessons/implementing-graphs-edge-list-adjacency-list-adjacency-matrix">a matrix</a> of size <code>m*n</code> have a space complexity of <code>O(m*n)</code>.</li></ul><ul id="7aec79a6-341c-4a96-bcf5-e8456b56a9b3" class="bulleted-list"><li style="list-style-type:disc">If a <code>k-dimensional</code> array is used, where each dimension is <code>n</code>, then the algorithm has a space complexity of <code>O(n^k)</code>.</li></ul><ul id="c4ea34b3-5304-4059-a8fa-a72febc549de" class="bulleted-list"><li style="list-style-type:disc">If you store an entire tree in a program and the tree has a branching factor <code>b</code> and depth <code>n</code> then the space complexity of the program/algorithm is exponential, i.e., <code>O(b^n)</code>.</li></ul><p id="33315a3a-3fe4-487a-bf4d-d3e02f9557fa" class="">This way the complexity categorizes algorithms on the basis of their space requirements. The figure below shows the varying space requirements for different categories of space complexity.</p><figure id="dc35cea1-11ab-4970-b824-775af2c199e2" class="image"><img style="width:2472px" src="Advanced%20Recursion%20Coding%20&amp;%20Analysis%205df0c658ddec43fd8bb82650a725effd/Screenshot_2023-05-10_at_7.43.22_PM.png"/></a></figure><h3 id="1a7cb082-9a32-491a-83a2-39c02176a529" class=""><strong>Space used by recursive algorithms</strong></h3><p id="c3005511-f40d-425a-92ab-052ae863e773" class="">The space used by recursive algorithms depends on the records being placed on the activation stack. The general rule is to count the maximum number of activation records on the stack at any given time.</p><p id="ad4ffaf8-d901-46e5-8bb5-1c2af6d9a26d" class="">If you generate a <code>recursion tree</code> of the program, then the space complexity would depend upon the total levels (depth) of the tree. You also carefully need to consider the variables being placed on the activation stack. An array being passed by reference to each recursive call would count as <code>O(n)</code>. However, if the array is passed by value, then you need to take into account <strong>each copy</strong> of the array along with the maximum number of activation records in memory.</p><p id="5c58de00-134c-422d-ab15-86d553dc65ca" class="">In the example below, the recursion tree for the recursive computation of Fibonacci numbers is shown. The figure shows that there won&#x27;t be more than <code>O(n)</code> instances of the function <code>f</code> along any branch of the recursion tree at any given time. Hence the space complexity is <code>O(n)</code>.</p><figure id="30a36f18-3db2-412a-9daf-6881f4e0829d" class="image"><img style="width:2454px" src="Advanced%20Recursion%20Coding%20&amp;%20Analysis%205df0c658ddec43fd8bb82650a725effd/Screenshot_2023-05-10_at_7.44.07_PM.png"/></a></figure><h3 id="f74669d1-5c07-4d7c-a97a-70b699e783ba" class=""><strong>Example 1: Factorial</strong></h3><p id="e295ea5d-84c0-40ef-bb04-d1e3da6dab97" class="">Let&#x27;s look at the classic problem of computing the factorial of a number. We&#x27;ll discuss both the iterative case and the recursive solution.</p><h3 id="52cdba39-99ea-47a2-a7e2-819ccf64ab63" class=""><strong>Iterative Solution</strong></h3><p id="27e61a33-e752-4bfe-a005-57de00f5e2e3" class="">The pseudo-code for the iterative solution is given below:</p><pre id="268cc660-8a45-43c4-a4cd-7580911a41f3" class="code"><code>Function: factorial(n)
Returns:  Factorial of the number n

Method:
result = 1
for i = (1..n)
{
	result = result * i
}

return result</code></pre><p id="a576989c-daed-4268-b9c9-02b5e9befe96" class="">When we look at the <code>factorial</code> function, we can see that it uses the variable <code>n</code>, <code>result</code> and <code>i</code>. No matter how large the number <code>n</code> is, we always use these three variables to compute the factorial. Hence, the space complexity of this function is O(1). It means we can compute the factorial of any number in constant space.</p><h3 id="7d26be86-03a4-4a2b-a657-c227985ccb43" class=""><strong>Recursive Solution</strong></h3><p id="c1eed48e-87cd-408c-9934-9355bac2b979" class="">The following is a recursive solution to computing the factorial:</p><pre id="72fb1334-6a95-4923-92ac-05b774eab0e6" class="code"><code>Function: factorialRecursive(n)
Returns:  Factorial of the number n

Method:
if n==0
	return 1

result = factorialRecursive(n-1)*n
return result</code></pre><p id="8c4dc3d7-a272-474e-95e5-56b93c41aab3" class="">When we look at the recursive solution, we can see that there are n recursive calls to <code>factorialRecursive</code> function. Each call maintains a record on the activation stack. The stack holds a copy of the variables <code>n</code> and <code>result</code>. Hence, the space complexity of the recursive version of factorial is O(n).</p><h3 id="77df8042-c769-45a3-9eda-bf620d7d87ec" class=""><strong>Example 2: Binary Search</strong></h3><p id="09904d7a-ed0d-4905-be30-891903e530fc" class="">Let&#x27;s take the example of binary search for finding a value in a sorted array. We&#x27;ll look at both the iterative and recursive solution.</p><h3 id="4611372c-c418-4846-97aa-91373a566725" class=""><strong>Iterative Solution</strong></h3><pre id="587deb04-4e3a-4aa4-9548-dfc6d5f90762" class="code code-wrap"><code>Function: binarySearch(arr, n, value)
Returns:  True/False

Method:
lower = 0
upper = n-1
found = false
while(lower&lt;=upper and !found)
{
	mid = (lower+upper)/2
	if arr[mid] &lt; value
		lower = mid+1
	else if arr[mid] &gt; value
		upper = mid-1
	else
		found = true
}
return found</code></pre><p id="2abc40fc-c8ba-4116-9e7b-475ea6209923" class="">The space complexity of the iterative solution can easily be computed as follows: 1. Input space: O(n) 1. Auxiliary space with variables (<code>n</code>, <code>value</code>, <code>lower</code>, <code>upper</code>, <code>found</code>, <code>mid</code>): O(1) 1. Overall space complexity counting the input and auxiliary space: O(n)</p><h3 id="6276d827-3814-404c-809a-864f47bb0944" class=""><strong>Recursive Solution</strong></h3><p id="e0cbdad8-1443-4a12-935c-e4a1f61a4ef3" class="">Given below is the pseudo-code for the recursive version of binarySearch:</p><pre id="f18ab195-a07d-4aef-a0b7-3e237b5af7ba" class="code"><code>Function: binarySearchRecursive(arr, value, lower, upper)
Returns:  True/False
Call this function for array size n using: binarySearchRecursive(arr, value, 0, n-1)

Method:
if lower &gt;= upper
	return false
mid = (lower+upper)/2
if arr[mid] == value
	return true
if arr[mid] &lt; value
	return binarySearchRecursive(arr, value, mid+1, upper)

return binarySearchRecursive(arr, value, lower, mid-1)</code></pre><p id="388930c3-f8a2-46fa-add8-9ada318faaa7" class="">Here, the recursive calls generate the activation stack. Each record on the stack holds a separate copy of the variables <code>lower</code>, <code>upper</code>, <code>mid</code> and <code>value</code>. The array can be passed by reference so a separate copy of the array is not created for each function call. As we can have <code>O(log(n))</code> calls to binarySearchRecursive function, the space complexity of the recursive version should include the <code>O(log(n))</code> auxiliary space. Hence, the overall space complexity is:</p><ol type="1" id="3ab3e6f4-f45f-4cd2-b215-2d7472dc38b8" class="numbered-list" start="1"><li>Input space: <code>O(n)</code></li></ol><ol type="1" id="c05b594a-3e97-4a57-88e5-4c6060abd5cd" class="numbered-list" start="2"><li>Auxiliary space for recursive calls involving <code>O(log n)</code> records created on stack: <code>O(log n)</code></li></ol><ol type="1" id="064c401d-fefc-4609-a506-1bd8f2d94fe3" class="numbered-list" start="3"><li>Overall space complexity counting the input and auxiliary space <code>O(n)</code></li></ol><h2 id="33d938ff-2b7d-4166-b391-b38958e44f21" class="block-color-default"><mark class="highlight-red"><strong>Space Complexity of Various Sorting Algorithms</strong></mark></h2><p id="67244857-9a0e-499b-bbdb-26da99842e5c" class="">The input space for all sorting algorithms is at least O(n), where n is the size of the array. It is also important to understand the auxiliary space being used by that algorithm.</p><ol type="1" id="5b3e0cf7-3d8e-434e-b6de-984cae4365d2" class="numbered-list" start="1"><li><strong>Bubble sort</strong>: The sorting is done in place and there is generally one extra variable used to store the temporary location for swapping successive items. Hence, the auxiliary space used is <code>O(1)</code>.</li></ol><ol type="1" id="84bddf05-196b-4702-b565-35069c26b3de" class="numbered-list" start="2"><li><strong>Insertion sort</strong>: The case is the same as bubble sort. The sorting is done in place with a constant number of extra variables, so the auxiliary space used in <code>O(1)</code>.</li></ol><ol type="1" id="2ff41565-531b-4572-9d30-253296c08590" class="numbered-list" start="3"><li><strong>Merge sort</strong>: In merge sort, we split the array into two and merge the two sub-arrays by using a temporary array. The temporary array is the same size as the input array, hence, the auxiliary space required is <code>O(n)</code>.</li></ol><ol type="1" id="67903347-d50b-464c-aeab-72c6b2db5897" class="numbered-list" start="4"><li><strong>Heap sort</strong>: Heap sort is also implemented in place and hence the auxiliary space required is <code>O(1)</code>.</li></ol><ol type="1" id="5c55c0a1-405a-4735-a1c0-38d1f2998f3d" class="numbered-list" start="5"><li><strong>Quick sort</strong>: Depending on how you implement quick sort, generally you would need <code>O(log(n))</code> additional space to sort an array.</li></ol><p id="a3532a10-1175-4e51-9b9f-2ece36d39101" class="">
</p><h2 id="95350cc6-10dc-496e-b29c-29d5927cc5e1" class="block-color-default"><mark class="highlight-blue">Activity 1 </mark></h2><p id="271b70b2-3193-417b-8917-ce459253e28d" class=""><strong>A. True or False: </strong></p><ol type="1" id="e4406096-2624-4bd6-9fb9-9ef9bc1d5c9e" class="numbered-list" start="1"><li>Recursive functions are based on the divide and conquer principle.</li></ol><ol type="1" id="419c50d8-eabd-4a43-aff4-fff7c06cd1a2" class="numbered-list" start="2"><li>Iteration is a technique that involves a function calling itself. </li></ol><ol type="1" id="f0030d8d-03b6-4715-8223-337afaf87164" class="numbered-list" start="3"><li>Both recursion and iteration involve repeatedly executing a set of instructions.</li></ol><ol type="1" id="fc2f9972-e644-4485-bac0-bd04ef23fb30" class="numbered-list" start="4"><li>When determining the optimal recursion algorithm, problem characteristics such as input size and data structure should not be considered. </li></ol><p id="fd485e8c-56bf-4d75-8a25-89c7b3a95315" class=""><strong>B. Fill in the blanks:</strong></p><ol type="1" id="f9217143-2bed-487d-9682-3d60daf1b812" class="numbered-list" start="1"><li>A __________<strong>(heap/stack/hashtable)</strong> is a data structure that allows efficient insertion, deletion, and search operations on a collection of items.</li></ol><ol type="1" id="44969c4a-f99f-45ae-a1c4-9c3c92b39666" class="numbered-list" start="2"><li>The worst-case time complexity of the quicksort algorithm is __________<strong>( O(log n)/O(n)/O(n ^ 2) )</strong>.</li></ol><ol type="1" id="746543cf-dbbb-4afd-a99f-61a6e51f6660" class="numbered-list" start="3"><li>The __________ <strong>(Breadth-first search/Dijkstra&#x27;s/Depth-first search) </strong>algorithm is used to find the shortest path between two vertices in a weighted graph.</li></ol><ol type="1" id="477ad62a-8ab9-40e2-9726-e22f0626601b" class="numbered-list" start="4"><li>The space used by recursive algorithms depends on the records being placed on the __________<strong>(activation stack/heap/queue)</strong>. The general rule is to count the maximum number of activation records on the stack at any given time.</li></ol><ul id="28e7f43c-2c5c-421d-9b3d-cd138db072f2" class="toggle"><li><details close=""><summary><strong>Answers</strong></summary><p id="60636700-e943-4945-9e7f-55d68825b6ca" class=""><strong>A. </strong> <strong>True or False</strong></p><ol type="1" id="23646a4d-0e89-46c5-b7e0-7ea69da4af5b" class="numbered-list" start="1"><li>True</li></ol><ol type="1" id="3d0124e3-8ca7-4a63-a698-08484f44ceae" class="numbered-list" start="2"><li>False</li></ol><ol type="1" id="1545378f-3387-4895-b489-118e170882aa" class="numbered-list" start="3"><li>True</li></ol><ol type="1" id="c83c63b7-c346-46d8-93e5-5d135216f766" class="numbered-list" start="4"><li>False</li></ol><p id="9659583b-7577-4343-bd11-46401b2cccef" class=""><strong>B. Fill in the blanks</strong></p><ol type="1" id="40908701-1189-4947-81f1-eb14cb4e02ae" class="numbered-list" start="1"><li>Hash table</li></ol><ol type="1" id="81de89f8-350e-487b-9040-528fda5a2e36" class="numbered-list" start="2"><li>O(n^2)</li></ol><ol type="1" id="5d2c8961-a071-4f72-948e-d407d4dd1b3d" class="numbered-list" start="3"><li>Dijkstra&#x27;s</li></ol><ol type="1" id="21ab106b-7aba-4da5-8e2a-eb7b0fc9a983" class="numbered-list" start="4"><li>activation stack</li></ol></details></li></ul><p id="651030f0-9b3e-46a9-a012-c65ac9bb1ad4" class="">
</p><h2 id="6429f514-1e09-4112-898d-46b6814d9c8a" class=""><mark class="highlight-red">Determining Optimal Recursion Algorithms for Specific Problems</mark></h2><p id="4e2ab379-2166-42e3-9878-024dc52a8e79" class="">When determining the optimal recursion algorithm for a specific problem, there are several factors to consider:</p><ol type="1" id="f4176305-08d0-4a2c-a0d4-eed211c59446" class="numbered-list" start="1"><li><strong>Problem characteristics:</strong> The problem characteristics, such as the input size, data structure, and complexity, should be considered when choosing a recursion algorithm. For example, some problems may require divide-and-conquer algorithms that break the problem into smaller subproblems, while others may require dynamic programming algorithms that build a solution by solving smaller subproblems in a specific order.</li></ol><ol type="1" id="c8d80a71-e75d-40a2-92f7-7666aa5b0e51" class="numbered-list" start="2"><li><strong>Time and space complexity:</strong> The time and space complexity of the algorithm should be analyzed to ensure that the algorithm is efficient for the given problem size and input type. It is essential to choose an algorithm with a reasonable time and space complexity that meets the problem requirements and constraints.</li></ol><ol type="1" id="c02c3538-ce25-4f74-8a0b-b1889f2c08f1" class="numbered-list" start="3"><li><strong>Recursion depth:</strong> The recursion depth is the number of times a function calls itself. It is important to ensure that the recursion depth is within the memory limits of the system. If the recursion depth is too large, it can lead to stack overflow errors.</li></ol><ol type="1" id="bbd31916-2f1c-4707-819f-86e31dfdb6a9" class="numbered-list" start="4"><li><strong>Memoization:</strong> Memoization can be used to optimize recursive algorithms that perform repetitive computations by storing the results of previous function calls and reusing them instead of recomputing them. This technique can be useful for reducing the time complexity of some recursive algorithms.</li></ol><ol type="1" id="5437921e-2b1a-4d4d-ad2a-d866c1887087" class="numbered-list" start="5"><li><strong>Tail recursion:</strong> Tail recursion optimization can be used to reduce both time and space complexity. This technique involves transforming a recursive algorithm into an equivalent iterative algorithm that uses constant space.</li></ol><p id="7a4a0864-f5da-41ee-978f-dc450fca3f63" class="">Overall, it is important to choose the optimal recursion algorithm that balances the tradeoffs between time and space complexity for the specific problem at hand. By considering the problem characteristics, analyzing the time and space complexity, and using optimization techniques such as memoization and tail recursion, the most efficient recursive algorithm can be determined.</p><h2 id="ca028713-1218-44c1-ad1c-ac21a427a51e" class="block-color-default"><mark class="highlight-red">Tradeoffs between Time and Space Complexity in recursion Algorithms</mark></h2><p id="afd5111b-6526-4ca4-b10f-8b8a91fff8d7" class="">Recursive algorithms, like other algorithms, have tradeoffs between time and space complexity that need to be considered when designing and implementing them. Here are some of the general tradeoffs to keep in mind:</p><ol type="1" id="9e4512f3-50f6-4d2f-aed1-d048a0201559" class="numbered-list" start="1"><li><strong>Time complexity:</strong> Recursive algorithms can have high time complexity due to the recursive calls. The time complexity can be affected by the number of recursive calls, the size of the input, and the operations performed at each recursion level. Generally, recursive algorithms with high time complexity are not suitable for large inputs or applications that require fast processing.</li></ol><ol type="1" id="ff7221e7-77f7-49c1-b270-614e53a27614" class="numbered-list" start="2"><li><strong>Space complexity:</strong> Recursive algorithms can also have high space complexity due to the recursive calls. Each recursive call creates a new stack frame that uses memory to store variables and other information. If the number of recursive calls is large, the space required can exceed the available memory. In such cases, the algorithm may need to be modified to reduce the space complexity or use other techniques such as dynamic programming to optimize the memory usage.</li></ol><ol type="1" id="f296bc67-b6ab-4938-a74f-f35af2d2fdd3" class="numbered-list" start="3"><li><strong>Tail recursion:</strong> Tail recursion optimization can be used to reduce both time and space complexity. This technique involves transforming a recursive algorithm into an equivalent iterative algorithm that uses constant space. The recursive function&#x27;s final call is replaced with a loop that updates the function&#x27;s arguments instead of creating a new stack frame. This technique can reduce the number of recursive calls and memory usage, making the algorithm more efficient.</li></ol><ol type="1" id="d034e54f-b70a-484e-a993-959ccc5425b8" class="numbered-list" start="4"><li><strong>Memoization:</strong> Memoization can be used to reduce time complexity by storing the results of previous function calls and reusing them instead of recomputing them. This technique can be useful for recursive algorithms that perform repetitive computations, such as Fibonacci series or dynamic programming.</li></ol><p id="f3df53e7-7b3b-49b9-8947-eb803b1764bc" class="">Overall, the choice of whether to use a recursive or iterative algorithm depends on the problem&#x27;s requirements and constraints. It is essential to carefully analyze the time and space complexity of the algorithm and make an informed decision based on the input size, memory availability, and performance requirements.</p><h2 id="4efc3707-58e8-40fa-8beb-c40410b6792e" class="block-color-default"><mark class="highlight-red">Real-World Applications of Recursion Algorithm</mark></h2><p id="084b58ec-d5b0-48c4-8f6e-e3e4feb63c77" class="">Recursion algorithms have real-world applications across various domains, including computer science, mathematics, physics, and biology. Here are some examples:</p><ol type="1" id="fe6f47ac-c4c1-423d-9583-d9fce6b98574" class="numbered-list" start="1"><li><strong>Tree Traversal:</strong> Recursion is commonly used for traversing trees in computer science, such as in file systems, website navigation, or database management.</li></ol><ol type="1" id="7e21237d-6f49-4013-8bb3-00f7f5b782e2" class="numbered-list" start="2"><li><strong>Sorting Algorithms:</strong> Many sorting algorithms, such as quicksort, merge sort, and heap sort, are implemented using recursion.</li></ol><ol type="1" id="70fcc9d6-ace6-4ccd-90d1-f30bfeb1b67d" class="numbered-list" start="3"><li><strong>Fractals:</strong> Fractals are mathematical patterns that can be generated using recursions, such as the Mandelbrot set and the Sierpinski triangle.</li></ol><ol type="1" id="95c0bd8a-7cbc-4160-a37d-b562fd5e1fc0" class="numbered-list" start="4"><li><strong>Graphics and Animation:</strong> Graphics and animation programs often use recursion to generate complex shapes or animations, such as fractal art or procedural terrain generation.</li></ol><ol type="1" id="05232a39-0174-4d49-a04a-c1fbc9a283a8" class="numbered-list" start="5"><li><strong>Searching Algorithms:</strong> Recursive searching algorithms, such as binary and depth-first search, are commonly used in computer science to search large datasets or find paths in graphs.</li></ol><ol type="1" id="fe886ce1-e90a-4641-a9fc-bd8619837371" class="numbered-list" start="6"><li><strong>Backtracking Algorithms:</strong> Backtracking algorithms, which are used to solve problems by trying out different solutions and undoing them if they do not work, are often implemented using recursion.</li></ol><ol type="1" id="64f091f4-2b46-4f34-9e53-3345be3fb5cd" class="numbered-list" start="7"><li><strong>Natural Language Processing:</strong> Recursive algorithms are also used in natural language processing for parsing and analyzing sentences, such as in syntax trees.</li></ol><p id="96f96014-3178-4562-83a1-a82b0a20b744" class="">Overall, recursion algorithms have numerous real-world applications and are widely used in computer science and other fields. Their ability to break down complex problems into smaller subproblems and solve them recursively makes them a powerful tool for solving complex problems efficiently.</p><p id="dc73cee2-4d6a-4c45-a854-106e90e1258f" class="">
</p><h2 id="698adacf-f430-4ea6-a015-912451f130e0" class="block-color-default"><mark class="highlight-blue">Explore Further</mark></h2><p id="a05e04cd-1006-4a1f-a414-4aaf1a894027" class=""><mark class="highlight-orange"><strong>Uncover and unlock new insights as you dive into the captivating content found in the provided link.</strong></mark></p><p id="5190006e-c092-4e32-95d2-e0c1e7b880bb" class=""><strong>Fractal: </strong><a href="https://medium.com/@yortuc/fractal-fun-with-javascript-2102d03ad22b">https://medium.com/@yortuc/fractal-fun-with-javascript-2102d03ad22b</a> <mark class="highlight-red"><strong>and</strong></mark> <a href="https://www.cs.cornell.edu/courses/cs212/1998sp/handouts/Fractals/similar.html">https://www.cs.cornell.edu/courses/cs212/1998sp/handouts/Fractals/similar.html</a></p><p id="2cb101dd-a26b-48e4-8da7-1c6e180abc46" class="">
</p><p id="7958eab7-ba61-4d14-b01b-9ca74ba3791d" class=""><mark class="highlight-orange"><strong>Tackle these questions head-on!</strong></mark></p><p id="d5c65956-2f3c-4714-a4f5-2a1022deb4ed" class=""><strong>Consider a fractal pattern formed by repeatedly dividing a line segment into three equal parts and replacing the middle third with two smaller line segments, each one-third the length of the original segment. This process is repeated infinitely.</strong></p><ol type="1" id="69ad9502-66fc-4017-a699-040842b4d2cc" class="numbered-list" start="1"><li>Start with a line segment of length 1.</li></ol><ol type="1" id="9ed64291-71e3-4bcd-9678-a964cc6b06e3" class="numbered-list" start="2"><li>After the first iteration, we have four line segments, each one-third the length of the original segment.</li></ol><ol type="1" id="391bdea9-1a1f-4911-9289-d5c30854d81a" class="numbered-list" start="3"><li>After the second iteration, we have 16 line segments, each one-ninth the length of the original segment.</li></ol><ol type="1" id="be0f2b39-4597-46dc-ad60-46a67efa97a8" class="numbered-list" start="4"><li>This process continues, creating more line segments with each iteration.</li></ol><p id="c1985d23-98c3-448b-9979-1ae819fbd4d9" class=""><strong>What is the fractal dimension of this fractal pattern?</strong></p><p id="96dc9f4d-ec13-4f83-b9c4-92c19c32c838" class="">(A) 0
(B) 1
(C) 2
(D) 3
(E) Cannot be determined</p><p id="6e008450-ab80-46d7-8880-594eb8f0ddb6" class="">(<strong>Hint</strong>: Consider the relationship between the number of line segments and their lengths after each iteration.)</p><ul id="aa202285-7a72-4473-b9ce-fbbe1cfb7c76" class="toggle"><li><details close=""><summary><strong>Answer</strong></summary><p id="f3c542a5-468f-4a89-b403-006b404b18dd" class=""><strong>B) 1</strong></p><p id="52ee7be2-523c-4b70-add5-b6a6f6710798" class="">The fractal dimension of the described fractal pattern can be calculated using the concept of self-similarity and the relationship between the number of line segments and their lengths.</p><p id="20be3ad5-9fe2-4679-b59f-65803b2ce61c" class="">In this case, after each iteration, the number of line segments increases by a factor of 4 (2 segments are added for each existing segment), and the length of each segment decreases by a factor of 3.</p><p id="f20a0cad-3bd2-4142-b632-e5a0f880d78e" class="">The fractal dimension (D) can be determined using the formula:</p><p id="51500582-53fe-4ac4-a57f-24876389e9a7" class="">D = log(N) / log(L)</p><p id="75bdf65b-ec40-4a07-abbb-7d3c304d23d5" class="">Where N is the number of line segments and L is the scaling factor (length ratio) between successive iterations.</p><p id="8cfb00cd-d705-4b9e-b1ee-dc5da36e415e" class="">For the given fractal pattern, N = 4 (number of line segments after each iteration) and L = 1/3 (scaling factor).</p><p id="93137c3b-ad76-4497-b113-f2e2109c0de3" class="">Calculating the fractal dimension:</p><p id="ae4f3050-2c59-4030-ab79-1400f47de747" class="">D = log(4) / log(1/3)
D = 2 / (-1.585)
D ≈ -1.26</p><p id="4a8848f2-c27b-46d3-b108-959b0594f685" class="">Since the calculated fractal dimension is approximately -1.26, which is less than 1, the correct answer is: B) 1</p><p id="d7a2f67b-f19d-4e2b-b9e9-6848b58de666" class="">The fractal dimension of this fractal pattern is 1, indicating a fractal structure with a fractional dimension between 1 and 2.</p></details></li></ul><h1 id="252245d1-b0bf-4d3f-8340-b3337ee42919" class=""><mark class="highlight-brown">Summary</mark></h1><h2 id="453966b1-bf44-4440-82cd-7bb90e98dc0a" class="block-color-default"><mark class="highlight-red">What did we learn?</mark></h2><ul id="6f26f052-415a-4b14-a42f-060213fc4309" class="bulleted-list"><li style="list-style-type:disc">Recursion can be a powerful tool for solving certain types of problems, but it can also be computationally expensive in terms of time and space complexity.</li></ul><ul id="54378dcc-9f93-4c91-a00c-60fb32b0b8b4" class="bulleted-list"><li style="list-style-type:disc">The time complexity of a recursive algorithm can be analyzed by considering the number of recursive calls made and the time required to solve each subproblem.</li></ul><ul id="ddcf0924-5ada-4069-90ca-ad45b75de1c9" class="bulleted-list"><li style="list-style-type:disc">The space complexity of a recursive algorithm can be analyzed by considering the maximum depth of recursion and the amount of memory required to store intermediate results.</li></ul><ul id="ae70ed64-f13f-41ae-bdef-fb41110edfd2" class="bulleted-list"><li style="list-style-type:disc">Memoization is a technique that can be used to reduce the time complexity of recursive algorithms by storing intermediate results in a lookup table to avoid redundant calculations.</li></ul><ul id="d7929e45-3232-4cfd-8590-88c429420bff" class="bulleted-list"><li style="list-style-type:disc">The Master Theorem is a powerful tool for analyzing the time complexity of recursive algorithms with a specific structure, such as the divide-and-conquer approach.</li></ul><ul id="629d9936-2d0d-4c0c-b829-12827c8efc6c" class="bulleted-list"><li style="list-style-type:disc">When analyzing the time complexity of a recursive algorithm, it is important to consider the worst-case scenario, which is the scenario that requires the most amount of time to complete.</li></ul><ul id="9d5c1512-5867-4800-85b5-866789fb427d" class="bulleted-list"><li style="list-style-type:disc">In general, the time complexity of a recursive algorithm that divides the problem into k subproblems of size n/k each can be expressed as O(n log k), assuming that the time required to solve each subproblem is O(n).</li></ul><ul id="3f5c5b55-fb5d-481d-a82a-2891503f40e0" class="bulleted-list"><li style="list-style-type:disc">The space complexity of a recursive algorithm can be influenced by several factors, including the number of variables that need to be stored, the size of the input data, and the depth of recursion.</li></ul><h2 id="357074f6-ebc8-4f6d-92a2-ff533b53b13c" class=""><mark class="highlight-red">Shortcomings &amp; Challenges</mark></h2><ul id="944a0a96-4199-43bb-8502-9ebff83ac1ba" class="bulleted-list"><li style="list-style-type:disc">The analysis is complex and time-consuming.</li></ul><ul id="05baf635-1185-4850-b72d-4c4d2263f0e6" class="bulleted-list"><li style="list-style-type:disc">Optimization is challenging.</li></ul><ul id="0572aaad-8ac2-462a-987e-cb1a9876ab41" class="bulleted-list"><li style="list-style-type:disc">Input data variability affects performance.</li></ul><ul id="df4e46cd-ccf8-4bf4-872d-79eadfb31330" class="bulleted-list"><li style="list-style-type:disc">Some techniques are only applicable to specific types of recursive algorithms.</li></ul><ul id="12f894ac-f5a5-4bf6-8dd4-00b3c5a36a20" class="bulleted-list"><li style="list-style-type:disc">Debugging is difficult, particularly for complex structures.</li></ul><h2 id="bc6799ef-4443-4943-a91c-2eed5bfd9390" class="block-color-default"><mark class="highlight-red">Best practices</mark></h2><ul id="743cf281-70ed-41ec-ad37-da2ddca6c78d" class="bulleted-list"><li style="list-style-type:disc">Identify the base case and the recursive case.</li></ul><ul id="6e85c53b-5aa1-4fc6-b404-59da2eab6723" class="bulleted-list"><li style="list-style-type:disc">Use memoization to improve efficiency.</li></ul><ul id="6fd0516c-d9ee-4e92-b8a7-b578e2dfe8c9" class="bulleted-list"><li style="list-style-type:disc">Use Master Theorem if applicable.</li></ul><ul id="f1c8987b-74fc-409f-88bc-69e5d577bcaa" class="bulleted-list"><li style="list-style-type:disc">Use visual aids to aid understanding.</li></ul><ul id="6e03ef5e-a605-4aaf-8d7c-3dcaceb1a3ce" class="bulleted-list"><li style="list-style-type:disc">Test and optimize the algorithm.</li></ul><h2 id="37b2b92b-7768-47ee-a78c-5d364379cb4d" class="block-color-default"><mark class="highlight-red">Enhance Your Knowledge</mark></h2><ul id="fd559dc2-be60-4712-a297-8c5d75e99bca" class="bulleted-list"><li style="list-style-type:disc"><a href="https://github.com/trekhleb/javascript-algorithms/">https://github.com/trekhleb/javascript-algorithms/</a> - This repository includes JavaScript implementations of a range of common algorithms and data structures, including recursive algorithms, with explanations of their time and space complexity.</li></ul><ul id="492fe44c-a564-47ec-aa85-d45e99ee11a6" class="bulleted-list"><li style="list-style-type:disc"><a href="https://github.com/TheAlgorithms/Javascript">https://github.com/TheAlgorithms/Javascript</a> - This repository includes JavaScript algorithms</li></ul><p id="c9e1d4d8-329f-4969-a3df-d718262843d6" class="">
</p></div></article></body></html>
